{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf830
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs72 \cf0 Project 3\

\fs24 \

\b Scope: 
\b0 Create a method for finding the hands in an image.\
\

\b Approach 1:
\b0 \
Load the image\
Convert to HSV\
Threshold for certain skin range\
Find the second and third largest blobs - (the first is the head, the second and third are the hands)\

\b Assume 
\b0 the hands are an extremity (hanging down) and no arm is showing\
Draw boxes around these of size average radius from center of blob\
Display the image with the hands in the boxes \

\b Approach 1 failed: there is no common range for skin, as it changes color under different kinds of light (due to its semi transparent nature). You will have to take a new approach, such as the one detailed here: http://www.robots.ox.ac.uk/~vgg/research/hands/\
\
\
Approach 2:\
Following model here: 
\b0 http://www.pyimagesearch.com/2015/03/23/sliding-windows-for-object-detection-with-python-and-opencv/\
\
Load the image\
Use learning to detect a feature in the image (the hands)\
Draw boxes around these of size average radius from center of blob\
Display the image with the hands in the boxes\
}